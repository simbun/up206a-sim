{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372167a9-b4a4-464a-a8dd-d80f24a5ff6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Housing Price Index Change in the City of Los Angeles from 2010 to 2019\n",
    "\n",
    "## **Research Question**: Do parks in the city of Los Angeles have an effect on housing prices and change in tenure from 2010 to 2019?\n",
    "\n",
    "My portion of the assignment is looking at housing prices in the LA. I used the 2010 and 2019 FHFA Annual House Price Indexes to calculate the percent change in housing prices in the City of Los Angeles. This data is in census tracts. We were curious to see if there is a relationship between access to parks and housing price trends. If there is a concentration of housing prices increasing in an area with parks, then nearby parks may be a factor that increases home values, which may be inducing gentrification.\n",
    "\n",
    "FHFA Housing Price Index:\n",
    "- https://www.fhfa.gov/DataTools/Downloads/Pages/House-Price-Index-Datasets.aspx\n",
    "\n",
    "ACS Data on Tenure:\n",
    "- [ACS 5-YR Table B25003](https://censusreporter.org/data/table/?table=B25003&geo_ids=16000US0644000,140|16000US0644000&primary_geo_id=16000US0644000)\n",
    "- [Download Link](https://api.dokku.censusreporter.org/1.0/data/download/acs2019_5yr?table_ids=B25003&geo_ids=16000US0644000,140|16000US0644000&format=geojson)\n",
    "\n",
    "Trust for Public Land's ParkScore Map\n",
    "- https://www.tpl.org/city/los-angeles-california\n",
    "- https://www.tpl.org/parkserve/downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5d851-18a1-426e-8587-62841089b0de",
   "metadata": {},
   "source": [
    "### I've broken up my notebook into two parts because the kernel kept crashing when it was one notebook. \n",
    "## Importing and Cleaning Up Housing Price Data & Park Data\n",
    "[Sim's midterm notebook for reference](https://github.com/simbun/up206a-sim/blob/main/midterm/midterm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a6b951-b966-4b10-b532-f72e99d0dbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# to read and visualize spatial data\n",
    "import geopandas as gpd\n",
    "\n",
    "# to provide basemaps \n",
    "import contextily as ctx\n",
    "\n",
    "# to give more power to your figures (plots)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745b9fa-4a05-41f4-8f50-449ddc6df19b",
   "metadata": {},
   "source": [
    "`geofile` is a geojson from the ACS that has census tract data. the `fhfa` is a csv with the housing price index data from the FHFA. I merge these two files together so the data can be mapable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d000d14-b5fb-45b1-a5ac-ac3403678de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the geofile is file with the geometry element \n",
    "geofile = gpd.read_file('acs2019_5yr_B25003_14000US06037222001.geojson')\n",
    "\n",
    "# the fhfa is the csv file with the data i want to map\n",
    "fhfa = gpd.read_file('FHFA_HPI_Fixed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f93d5d2-fc14-4791-8b4a-5f071e9f9c44",
   "metadata": {},
   "source": [
    "Although I am just using the geofile for the geometry aspect, I still would like to clean up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e26b715-dab8-4ee5-9255-ad98b6f643be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1005 entries, 0 to 1004\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   geoid             1005 non-null   object  \n",
      " 1   name              1005 non-null   object  \n",
      " 2   B25003001         1005 non-null   float64 \n",
      " 3   B25003001, Error  1005 non-null   float64 \n",
      " 4   B25003002         1005 non-null   float64 \n",
      " 5   B25003002, Error  1005 non-null   float64 \n",
      " 6   B25003003         1005 non-null   float64 \n",
      " 7   B25003003, Error  1005 non-null   float64 \n",
      " 8   geometry          1005 non-null   geometry\n",
      "dtypes: float64(6), geometry(1), object(2)\n",
      "memory usage: 70.8+ KB\n"
     ]
    }
   ],
   "source": [
    "geofile. info(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24e9a55-7888-4beb-8355-a31a29ad099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing what columns to keep \n",
    "columns_to_keep= ['geoid','name','B25003001','B25003002','B25003003', 'geometry']\n",
    "# applying the function\n",
    "geofile=geofile[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af027df2-2c8b-413e-97fd-2b6a516bc02c",
   "metadata": {},
   "source": [
    "I am pulling the last two rows of data because I already know from experience that the last row is not census tract data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2d3da8-d0b0-4933-a073-b596ea135e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>name</th>\n",
       "      <th>B25003001</th>\n",
       "      <th>B25003002</th>\n",
       "      <th>B25003003</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>14000US06037990200</td>\n",
       "      <td>Census Tract 9902, Los Angeles, CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MULTIPOLYGON (((-118.63598 34.03255, -118.6325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>16000US0644000</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>1383869.0</td>\n",
       "      <td>509504.0</td>\n",
       "      <td>874365.0</td>\n",
       "      <td>MULTIPOLYGON (((-118.66818 34.18987, -118.6681...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geoid                                name  B25003001  \\\n",
       "1003  14000US06037990200  Census Tract 9902, Los Angeles, CA        0.0   \n",
       "1004      16000US0644000                     Los Angeles, CA  1383869.0   \n",
       "\n",
       "      B25003002  B25003003                                           geometry  \n",
       "1003        0.0        0.0  MULTIPOLYGON (((-118.63598 34.03255, -118.6325...  \n",
       "1004   509504.0   874365.0  MULTIPOLYGON (((-118.66818 34.18987, -118.6681...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geofile.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f91660-d1cd-4ff2-86bb-f1f5eefbc70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>name</th>\n",
       "      <th>B25003001</th>\n",
       "      <th>B25003002</th>\n",
       "      <th>B25003003</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>14000US06037990200</td>\n",
       "      <td>Census Tract 9902, Los Angeles, CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MULTIPOLYGON (((-118.63598 34.03255, -118.6325...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geoid                                name  B25003001  \\\n",
       "1003  14000US06037990200  Census Tract 9902, Los Angeles, CA        0.0   \n",
       "\n",
       "      B25003002  B25003003                                           geometry  \n",
       "1003        0.0        0.0  MULTIPOLYGON (((-118.63598 34.03255, -118.6325...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping this row because it is not a census tract\n",
    "geofile=geofile.drop([1004])\n",
    "# making sure it is dropped\n",
    "geofile.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adad58-b86b-46a6-b6f8-3792ca6b2354",
   "metadata": {},
   "source": [
    "I am now cleaning up the fhfa data and I am spending more time on this because this is a dataset that I am focusing on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44072903-e87a-44e9-a68c-d63e810835e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1640 entries, 0 to 1639\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   addition to geoid  1640 non-null   object  \n",
      " 1   geoid              1640 non-null   object  \n",
      " 2   field_3            1640 non-null   object  \n",
      " 3   hpi 2010           1640 non-null   object  \n",
      " 4   hpi 2019           1640 non-null   object  \n",
      " 5   % change           1640 non-null   object  \n",
      " 6   geometry           0 non-null      geometry\n",
      "dtypes: geometry(1), object(6)\n",
      "memory usage: 89.8+ KB\n"
     ]
    }
   ],
   "source": [
    "fhfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2ee14c-cb6b-429c-9b8c-a5137bdaf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing what columns to keep \n",
    "columns_to_keep= ['field_3','hpi 2010','hpi 2019','% change','geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b860e583-6766-40cb-a54b-daa8623b3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function\n",
    "fhfa=fhfa[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947cdf37-a042-4712-b839-c3c08a889dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['field_3', 'hpi 2010', 'hpi 2019', '% change', 'geometry']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the list for the fhfa columns so i can copy and paste it later and rename it\n",
    "list(fhfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f35e109-8750-4d4e-bea2-67193fba41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns\n",
    "fhfa.columns= ['geoid', 'hpi 2010', 'hpi 2019', 'pc_hpi', 'geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4db9a9d-0289-4094-8c19-0f43aaabd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cannot map objects so we must change them into floats, except for the geoid column\n",
    "fhfa['hpi 2010'] = fhfa ['hpi 2010'].astype(float)\n",
    "fhfa['hpi 2019'] = fhfa ['hpi 2019'].astype(float)\n",
    "fhfa['pc_hpi'] = fhfa ['pc_hpi'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c0b46-fa54-4a54-b590-d05f1b6b43ab",
   "metadata": {},
   "source": [
    "After cleaning up the datasets, I am merging the datat using the column, 'geoid'. This will make the fhfa dataset mappable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3da349-905f-4b7e-9d54-a43220f05991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the data\n",
    "fhfa=fhfa.merge(geofile,on= 'geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c1f7a5-65ee-44aa-867b-546a41a93708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>hpi 2010</th>\n",
       "      <th>hpi 2019</th>\n",
       "      <th>pc_hpi</th>\n",
       "      <th>geometry_x</th>\n",
       "      <th>name</th>\n",
       "      <th>B25003001</th>\n",
       "      <th>B25003002</th>\n",
       "      <th>B25003003</th>\n",
       "      <th>geometry_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>14000US06037297602</td>\n",
       "      <td>304.19</td>\n",
       "      <td>435.04</td>\n",
       "      <td>0.43</td>\n",
       "      <td>None</td>\n",
       "      <td>Census Tract 2976.02, Los Angeles, CA</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>MULTIPOLYGON (((-118.29286 33.72110, -118.2928...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  geoid  hpi 2010  hpi 2019  pc_hpi geometry_x  \\\n",
       "574  14000US06037297602    304.19    435.04    0.43       None   \n",
       "\n",
       "                                      name  B25003001  B25003002  B25003003  \\\n",
       "574  Census Tract 2976.02, Los Angeles, CA     1712.0      700.0     1012.0   \n",
       "\n",
       "                                            geometry_y  \n",
       "574  MULTIPOLYGON (((-118.29286 33.72110, -118.2928...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if it worked\n",
    "fhfa.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d74853-d3e0-461a-8d0d-58fbf4397700",
   "metadata": {},
   "source": [
    "It worked. Now I am cleaning up the data further, removing the columns from the geoid. I should have done this sooner but here we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b0c746-9ded-4825-af11-4ce162919413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming the columns i need to keep\n",
    "columns_to_keep= ['geoid','hpi 2010','hpi 2019','pc_hpi','name','geometry_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9f7129d-43f6-4544-97be-cdccae8ed87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing the function \n",
    "fhfa=fhfa[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e330fa-7800-4dbb-8187-05d2e38cc874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geoid', 'hpi 2010', 'hpi 2019', 'pc_hpi', 'name', 'geometry_y']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listing the column names so i can copy and paste\n",
    "# i only need to change the geometry_y to geometry\n",
    "# Ariana said if i didn't drop the y it would give me a hard time later \n",
    "list(fhfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27256738-14c7-4dc8-b89b-b5eb6321e53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>hpi 2010</th>\n",
       "      <th>hpi 2019</th>\n",
       "      <th>pc_hpi</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14000US06037101110</td>\n",
       "      <td>505.95</td>\n",
       "      <td>934.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Census Tract 1011.10, Los Angeles, CA</td>\n",
       "      <td>MULTIPOLYGON (((-118.30229 34.25870, -118.3009...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                geoid  hpi 2010  hpi 2019  pc_hpi  \\\n",
       "0  14000US06037101110    505.95    934.82    0.85   \n",
       "\n",
       "                                    name  \\\n",
       "0  Census Tract 1011.10, Los Angeles, CA   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-118.30229 34.25870, -118.3009...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming the columns\n",
    "fhfa.columns = ['geoid', 'hpi 2010', 'hpi 2019', 'pc_hpi', 'name', 'geometry']\n",
    "# checking to see if it worked \n",
    "fhfa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b9239-a3b9-4e4f-beb2-3c7f8be42091",
   "metadata": {},
   "source": [
    "The other main dataset I am working with is the parks data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f446052-cc6f-4343-a1f0-8b933313f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the parks data\n",
    "parks = gpd.read_file('SoCalParks.zip')\n",
    "parks.to_file('SoCalParks.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e788e6-4897-47b6-b694-6e48172fce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the followng data columns to strings\n",
    "parks['Park_Name'] = parks ['Park_Name'].astype(str)\n",
    "parks['Park_Urban'] = parks ['Park_Urban'].astype(str)\n",
    "parks['Park_Desig'] = parks ['Park_Desig'].astype(str)\n",
    "parks['Park_Owner'] = parks ['Park_Owner'].astype(str)\n",
    "parks['Park_Local'] = parks ['Park_Local'].astype(str)\n",
    "parks['Park_Manag'] = parks ['Park_Manag'].astype(str)\n",
    "parks['Park_Loc_1'] = parks ['Park_Loc_1'].astype(str)\n",
    "parks['Park_Statu'] = parks ['Park_Statu'].astype(str)\n",
    "parks['Park_Est_D'] = parks ['Park_Est_D'].astype(str)\n",
    "parks['Park_Addre'] = parks ['Park_Addre'].astype(str)\n",
    "parks['Park_State'] = parks ['Park_State'].astype(str)\n",
    "parks['Park_Sta_1'] = parks ['Park_Sta_1'].astype(str)\n",
    "parks['Park_Count'] = parks ['Park_Count'].astype(str)   \n",
    "parks['Park_Cou_1'] = parks ['Park_Cou_1'].astype(str)     \n",
    "parks['Park_Place'] = parks ['Park_Place'].astype(str)\n",
    "parks['Park_Pla_1'] = parks ['Park_Pla_1'].astype(str)   \n",
    "parks['Park_Urb_1'] = parks ['Park_Urb_1'].astype(str)     \n",
    "parks['Park_Zip'] = parks ['Park_Zip'].astype(str)\n",
    "parks['Park_Bound'] = parks ['Park_Bound'].astype(str)   \n",
    "parks['Park_Sourc'] = parks ['Park_Sourc'].astype(str)     \n",
    "parks['Park_Feedb'] = parks ['Park_Feedb'].astype(str)\n",
    "parks['Park_DateA'] = parks ['Park_DateA'].astype(str) \n",
    "parks['DataShare_'] = parks ['DataShare_'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac21692-4ea5-49cf-a229-887c289a7a62",
   "metadata": {},
   "source": [
    "Next, I am mapping the percent change of the housing price and the parks in Los Angeles City. I am layering these two maps on top of each other to see where the parks and housing prices changes are. Ariana and I suspect that parks may have an influence on the housing prices. If we are right, we would see that the areas with the highest increase in housing prices are in close to proximity to parks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7398fe-27cd-4228-ae0b-00bbd5159df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# addressing the error as there is no Dataframe\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "# updating the fhfa data so it is a dataframe\n",
    "fhfa = GeoDataFrame(fhfa)\n",
    "\n",
    "parks_web_mercator = parks.to_crs(epsg=3857)\n",
    "fhfa_web_mercator = fhfa.to_crs(epsg=3857)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "# add the layer with ax=ax in the argument \n",
    "fhfa_web_mercator.plot(ax=ax,column='pc_hpi', cmap='OrRd', legend=True,alpha=0.8)\n",
    "parks_web_mercator[parks_web_mercator['Park_Place'] == 'Los Angeles city'].plot(ax=ax, color=\"darkgreen\",alpha= 0.8)\n",
    "                                            \n",
    "# turn off axis\n",
    "ax.axis ('off')\n",
    "                                            \n",
    "#set a title\n",
    "ax.set_title('Parks in LA City Compared to Percent Change in Housing Price Index', fontsize=24,pad=20)\n",
    "\n",
    "#add basemap\n",
    "ctx.add_basemap(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857cc5b9-043e-4359-ac5a-d2ccdd836b06",
   "metadata": {},
   "source": [
    "The areas that are more intensely red have the highest increases in housing prices, in terms of percentage. Note, for the legend the highest is 2.00 but please read it as 200%. So this map shows that the area with the highest increas in housing prices is in South LA and Central LA. However, these areas are lacking in parks. At a first glance, it seems we may have missed the mark with our assumption. However, even if the highest increase in housing prices is not close to parks, let's see if there is some statstical significance for our other data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bf511-2468-4c56-adfc-72b021a2eb2f",
   "metadata": {},
   "source": [
    "For the next part, we are starting the spatial autocorrelation work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197820d8-9bea-4a72-a22b-a6b10de0963b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spatial Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e44f01-cc30-4555-b0a3-09e33d56cae3",
   "metadata": {},
   "source": [
    "This will be my attempt to do spatial autocorrelation for housing price index in Los Angeles Census Tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1cd50d-70ec-4fe7-afa0-93e93d35fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import esda\n",
    "from esda.moran import Moran, Moran_Local\n",
    "\n",
    "import splot\n",
    "from splot.esda import moran_scatterplot, plot_moran, lisa_cluster,plot_moran_simulation\n",
    "\n",
    "import libpysal as lps\n",
    "\n",
    "# Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842113d-d738-4ec1-9a1f-9350ef4c377b",
   "metadata": {},
   "source": [
    "How many parks are there in each census block group? In order to answer this question, one must count the number of arrests that fall within each block group boundary. To do so, we conduct a spatial join.\n",
    "\n",
    "Do parks have an impact on percent change in housing prices? Does the number of parks in a census tract affect whether or not there is a negative/positive change in housing prices in an area? Is that value statistically significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be57b5a-935b-482f-8192-a0baf6013dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the dataset so it is a dataframe\n",
    "fhfa = GeoDataFrame(fhfa) # i did this one already but i think it should be good to have it all in one place\n",
    "parks= GeoDataFrame(parks)\n",
    "\n",
    "fhfa = fhfa.to_crs(epsg=3857)\n",
    "parks = parks.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0a6cd-7ede-4b9c-9815-c0bba97ad446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I am joining the parks and fhfa dataset. \n",
    "# from my understanding this is different from merging as we are not merging it using a column.\n",
    "parks_join = gpd.sjoin(parks,fhfa, how='left')\n",
    "\n",
    "# checking to see if the function worked\n",
    "parks_join.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84e408-86c3-49b1-a499-a565816f1760",
   "metadata": {},
   "source": [
    "So, I got stuck at this point when I followed the lab. When I had it as `join = gpd.sjoin(parks,fhfa, how='left')`, later on when I tried to join the `parks_by_ct` to the parks data, it would say error and that the data does not exist. When I looked at Ariana's notebook, I noticed she did not have the same problem. I was stumpt!! It took a lot of troubleshooting to figure out this simple solution but here we are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa344b-6b5a-4a95-8ff5-531b948f9e03",
   "metadata": {},
   "source": [
    "Next, we create another dataframe that counts parks by their corresponding census tracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf2d4a-3d5b-470c-8b07-09f50de0d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_by_ct = parks_join.geoid.value_counts().rename_axis('geoid').reset_index(name='parks_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b52c67-9019-4074-89e9-9b491c820cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_by_ct.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e658d25e-20e6-45b9-950d-09c1f918b015",
   "metadata": {},
   "source": [
    "The census tracts with the highest park count is 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470854a9-ad8d-43ea-b7df-d57b810794f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_by_ct[:20].plot.bar(figsize=(20,4),\n",
    "                          x= 'geoid',\n",
    "                          y='parks_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6b352-49f5-497a-8296-4af577baba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you read my markdown cell earlier, this is where i got stuck. x(\n",
    "# now we are merging the data using the geoid column.\n",
    "parks=parks_join.merge(parks_by_ct, on ='geoid') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8383bd-c020-4179-a59b-3ff29e1ab332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing if the merge worked. \n",
    "parks.sort_values(by=\"parks_count\").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee2bb0f-5380-46bc-badc-e63e1ac64bd8",
   "metadata": {},
   "source": [
    "We see that the census tracts with the highest park count is in Santa Monica Mountains Conservancy which makes sense. Though I am not really sure if there are homes there ( I have not been to Santa Monica Mountains) but the housing price changed by about 47% from 2010 to 2019. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d14883-6346-47b7-8584-305488726d20",
   "metadata": {},
   "source": [
    "## Normalizing: Parks per 10 percentage change of housing price index\n",
    "Rather than proceeding with an absolute count of parks, we are normalizing it by number of percent change of housing prices in the census tract. I thought it would be good to use 10% as an increment of measure since 100% may be too much. \n",
    "\n",
    "So I am attempting to normalize the number of parks by every 10% of change of housing price. That is what I am attempting but if I am not doing it correctly, please let me know because I am a bit confused. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d02141e-55e3-42eb-a34a-a1d750de8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks['parks_per_10'] = parks['parks_count']/(parks['pc_hpi'])*.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934ccce-a39a-4e42-aa4b-14756dd2d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.sort_values(by=\"parks_per_10\").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6f2c8-5143-4aa5-8302-a1de3399a876",
   "metadata": {},
   "source": [
    "Right now `pc_hpi` is a decimal but I am reading it as a percentage. So, if it reads 1.68, it is a 168% change. Should I be chang the `pc_hpi` column?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9224cc8-b749-4ba4-bd58-3ba2ebf2c646",
   "metadata": {},
   "source": [
    "Here, we sort the values by descending arrest rate, and only show a slice of the data, the top 20 geographies using the handy `[:20]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036d7da-12dc-4ea8-879b-b22c88eeb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,10))\n",
    "parks.sort_values(by='parks_per_10',ascending=False)[:20].plot(ax=ax,\n",
    "                                                                 color='darkgreen',\n",
    "                                                                 edgecolor='white',\n",
    "                                                                 alpha=0.5,legend=True)\n",
    "\n",
    "\n",
    "# title\n",
    "ax.set_title('Top 20 locations of Green Spaces per 10 Percent Change in Housing Price')\n",
    "\n",
    "# no axis\n",
    "ax.axis('off')\n",
    "\n",
    "# add a basemap\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed5aaa-4d30-40f2-8331-848ed2522558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bounding box coordinates for the arrest data\n",
    "minx, miny, maxx, maxy = parks.geometry.total_bounds\n",
    "print(minx)\n",
    "print(maxx)\n",
    "print(miny)\n",
    "print(maxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5b845-73fe-4b78-a078-85225e08dfbf",
   "metadata": {},
   "source": [
    "Adding the boundaries so we can see the full map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede15c4-139a-4050-a4aa-dc0afc4832f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,10))\n",
    "parks.sort_values(by='parks_per_10',ascending=False)[:20].plot(ax=ax,\n",
    "                                                                 color='darkgreen',\n",
    "                                                                 edgecolor='white',\n",
    "                                                                 alpha=0.9,legend=True)\n",
    "\n",
    "\n",
    "# title\n",
    "ax.set_title('Top 20 Locations of Green Spaces per 10 Housing Price Percent Changes')\n",
    "\n",
    "# no axis\n",
    "ax.axis('off')\n",
    "\n",
    "# use the bounding box coordinates to set the x and y limits\n",
    "ax.set_xlim(minx - 10, maxx + 10) # added/substracted value is to give some margin around total bounds\n",
    "ax.set_ylim(miny - 10, maxy + 10)\n",
    "\n",
    "# add a basemap\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f41e85-a223-4fe8-b674-81f113533713",
   "metadata": {},
   "source": [
    "I wonder if the data is skewed looking at this map since there is such a concentration of parks in the Santa Monica Mountains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e928e63a-8c8b-4b6e-859e-65646079963e",
   "metadata": {},
   "source": [
    "## Choropleth map of parks\n",
    "\n",
    "We ready to generate a choropleth map of parks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de8a6e-2623-41df-94fd-a962f76460b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "parks.plot(ax=ax,\n",
    "        column='parks_per_10',\n",
    "        legend=True,\n",
    "        alpha=0.8,\n",
    "        cmap='RdYlGn_r',\n",
    "        scheme='quantiles')\n",
    "\n",
    "ax.axis('off')\n",
    "ax.set_title('Parks per 10 Percent Change',fontsize=22)\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39484dc5-ea5d-4b4a-9eb6-f9bbe1d500ea",
   "metadata": {},
   "source": [
    "I believe this map is showing us that there is concentration of parks in the West, Northwest, and Northeast. For the next map, I will be incorporating the housing price percent change layer and comparing the concentration of parks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3adba-9a52-4b29-be6a-891fa45123e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_web_mercator = parks.to_crs(epsg=3857)\n",
    "fhfa_web_mercator = fhfa.to_crs(epsg=3857)\n",
    "\n",
    "\n",
    "# add the layer with ax=ax in the argument \n",
    "fig,ax = plt.subplots(figsize=(12,10))\n",
    "\n",
    "fhfa_web_mercator.plot(ax=ax,column='pc_hpi', cmap='OrRd', legend=True,alpha=0.8)\n",
    "\n",
    "\n",
    "parks.plot(ax=ax,\n",
    "        column='parks_per_10',\n",
    "        legend=True,\n",
    "        alpha=0.8,\n",
    "        cmap='PiYG',\n",
    "        scheme='quantiles')\n",
    "\n",
    "# title\n",
    "ax.set_title('Parks per 10 Percent Change')\n",
    "\n",
    "# no axis\n",
    "ax.axis('off')\n",
    "\n",
    "# add a basemap\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a8d9a-22b9-42e8-9b1b-4278cc8f1b18",
   "metadata": {},
   "source": [
    "Again, we see that the areas with the highest change in housing prices are not in areas with high concentrations of parks. In other words, the resulting map tells us that there does not appear to be spatial clusters of parks where high housing price changes are more prevalent. However, we cannot statistically back this up. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad00c20b-034a-4653-a9f1-e17cbdb95e87",
   "metadata": {},
   "source": [
    "## Please find my work on spatial weight, spatial lag, and etc in part 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
